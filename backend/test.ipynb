!pip install pdfplumber pinecone

import pdfplumber
from langchain.text_splitter import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer
from pinecone import Pinecone
import os

pc = Pinecone(api_key="pcsk_P5Pfd_LoH3ryXtGWHBbmVFjSRhsdJqxpmzBQyzkk1TefVrGd9TQdtah9Rpt6i1g1BENiN")
index_name = "document-search"

# Load embedding model
model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

def extract_text_from_pdf(pdf_path):
    text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text += page.extract_text() + "\n"
    return text

# Chunk the document
def chunk_text(text, chunk_size=500, chunk_overlap=100):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len
    )
    return text_splitter.split_text(text)

# Convert to embeddings and store in Pinecone
def store_embeddings(text_chunks):
    index = pc.Index(index_name)  # Connect to the Pinecone index
    embeddings = model.encode(text_chunks)  

    # Store in Pinecone
    for i, (chunk, embedding) in enumerate(zip(text_chunks, embeddings)):
        index.upsert(vectors=[(str(i), embedding.tolist(), {"chunk": chunk})])

    print("Embeddings stored successfully!")
    return index

query = "How can I apply for financial assistance for this course?"
query_embedding = model.encode(query).tolist()

results = index.query(vector=query_embedding, top_k=3, include_metadata=True)

if results["matches"]:
    best_match = results["matches"][0]
    answer = best_match["metadata"].get("chunk", "No relevant document found")
else:
    answer = "No relevant document found."

print("Answer:", answer)

pdf_text = extract_text_from_pdf("/content/financial aid course.pdf")
chunks = chunk_text(pdf_text)
index = store_embeddings(chunks)
